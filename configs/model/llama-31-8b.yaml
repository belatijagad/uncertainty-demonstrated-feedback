# @package model
name: Llama-3.1-8B-Instruct
device: "cuda"
attn_implementation: "sdpa"
name_or_path: "meta-llama/Llama-3.1-8B-Instruct"
use_bf16: true
