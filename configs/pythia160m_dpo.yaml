commit_message: "Test"
seed: 42

model:
  name_or_path: "experiments/pythia-160m-sft/model"

wandb:
  enabled: true
  project: "uncertainty-aware-alignment"
  name: "pythia160m_dpo"
  group: ["dpo"]
  tags: ["pythia", "160m"]
  notes: "DPO training on Pythia 160M"

dataset:
  name_or_path: "HuggingFaceH4/ultrafeedback_binarized"
  split: "train_prefs"
  batch_size: 4
  max_length: 1024
  num_workers: 1
  # float for fraction; int for count.
  subset_size: 0.1

optimizer:
  lr: 5.0e-6
  weight_decay: 0.01

trainer:
  sample_during_eval: true
  epochs: 1
  beta: 0.1
  warmup_steps: 100
  max_grad_norm: 1.0
  logging_steps: 10
  save_steps: 500
  eval_steps: 250
  push_to_hub: false
  repo_id: "belati/pythia160m_dpo"
