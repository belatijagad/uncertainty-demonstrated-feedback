run_dir: "experiments/SmolLM2-135M-Instruct-dpo"
seed: 42
epochs: 1

model:
  name_or_path: "HuggingFaceTB/SmolLM2-135M-Instruct" 
  output_path: "experiments/SmolLM2-135M-Instruct-dpo/model"
  beta: 0.1

dataset:
  name_or_path: "HuggingFaceH4/ultrafeedback_binarized"
  split: "train_prefs"
  batch_size: 4
  max_length: 1024
  num_workers: 1
  # float for fraction; int for count.
  subset_size: 0.1

optimizer:
  lr: 5.0e-6
  weight_decay: 0.01

scheduler:
  warmup_steps: 100

trainer:
  max_grad_norm: 1.0
  logging_steps: 10
  save_steps: 500
  eval_steps: 250
