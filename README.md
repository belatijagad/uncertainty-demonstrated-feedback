# Uncertainty Estimation for Demonstration Iterated Task Optimization

---

## Installation

```bash

```

## Dataset

## Implementation Roadmap

- [] Implement algorithms
    - [] RLHF with PPO
    - [x] DPO (IPO loss and SimPO options)
    - [] DITTO
    - [] UPO
    - [] UDITTO

- [] Miscellaneous
    - [] vLLM for faster inference (in DPO's limitation since they don't use vLLM)
        - [] RLHF with PPO
        - [] DPO
        - [] DITTO
        - [] UPO
        - [] UDITTO
    - [] Distributed training using FSDP
        - [] RLHF with PPO
        - [x] DPO
        - [] DITTO
        - [] UPO
        - [] UDITTO
    - [] Logging (logger, wandb)
        - [] RLHF with PPO
        - [x] DPO
        - [] DITTO
        - [] UPO
        - [] UDITTO
    